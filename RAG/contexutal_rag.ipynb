{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json \n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "from glob import glob\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\bhavi\\OneDrive\\Desktop\\langhcain_learning\\RAG\\rag_docs\\wikidata_rag_demo.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF DOCS ---- 1801\n",
      "page_content='{\"id\": \"71548\", \"title\": \"Chi-square distribution\", \"paragraphs\": [\"In probability theory and statistics, the chi-square distribution (also chi-squared or formula_1\\\\u00a0 distribution) is one of the most widely used theoretical probability distributions. Chi-square distribution with formula_2 degrees of freedom is written as formula_3. It is a special case of gamma distribution.\", \"Chi-square distribution is primarily used in statistical significance tests and confidence intervals. It is useful, because it is relatively easy to show that certain probability distributions come close to it, under certain conditions. One of these conditions is that the null hypothesis must be true. Another one is that the different random variables (or observations) must be independent of each other.\"]}' metadata={'source': 'C:\\\\Users\\\\bhavi\\\\OneDrive\\\\Desktop\\\\langhcain_learning\\\\RAG\\\\rag_docs\\\\wikidata_rag_demo.jsonl', 'seq_num': 4}\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(file_path=file_path,\n",
    "                    jq_schema=\".\",\n",
    "                    text_content=False,\n",
    "                    json_lines=True)\n",
    "\n",
    "wiki_docs = loader.load()\n",
    "print(\"LENGTH OF DOCS ----\",len(wiki_docs))\n",
    "print(wiki_docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ddata from json \n",
    "wikipedia_documents = []\n",
    "\n",
    "for doc in wiki_docs:\n",
    "    doc = json.loads(doc.page_content)\n",
    "    meta_data = {\"title\":doc[\"title\"],\n",
    "                 \"id\":doc[\"id\"],\n",
    "                 \"source\":\"wikipedia\",\n",
    "                 \"page\":1\n",
    "                 }\n",
    "    \n",
    "    data = \" \".join(doc[\"paragraphs\"])\n",
    "    wikipedia_documents.append(Document(page_content=data ,metadata=meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Dattatreya is the God who is an incarnation of the Divine Trinity Brahma, Vishnu and Siva. The word Datta means \"Given\", Datta is called so because the divine trinity have \"given\" themselves in the form of a son to the sage couple Guru Atri and Mata Anusuya. He is the son of Guru Atri, hence the name \"Atreya.\" In the Nath tradition, Dattatreya is seen as an Avatar or incarnation of the Lord Shiva and as the Adi-Guru (First Teacher) of the Adi-Nath sampradaya of the Nathas. Although Dattatreya was at first a \"Lord of Yoga\" with Tantric traits, he was adapted and assimilated into the more devotional cults; while still worshiped by millions of Hindus, he is approached more as a benevolent God than as a teacher of the highest essence of Indian thought. Though the Dattatreya of the Natha tradition coexisted and intermingled with the Puranic, Brahmanical tradition of the Datta sampradaya, here we shall focus almost exclusively on the earlier Tantric manifestation of Datta. Shri Gurudev Mahendranath had no doubt that Dattatreya was an historical figure. He stated that Datta was born on Wednesday, the fourteenth day of the full moon in the month of Margasirsa, though he does not mention the year.', metadata={'title': 'Dattatreya', 'id': '86394', 'source': 'wikipedia', 'page': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model \n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model=\"qwen/qwen3-32b\",\n",
    "                 temperature=0,\n",
    "                 max_tokens=None,\n",
    "                 api_key=api_key,\n",
    "                 timeout=None,\n",
    "                 max_retries=2,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model \n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model=\"qwen/qwen3-32b\",\n",
    "                 temperature=0,\n",
    "                 max_tokens=None,\n",
    "                 api_key=api_key,\n",
    "                 timeout=None,\n",
    "                 max_retries=2,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standard_chunks(file_path, chunk_size=1500, chunk_overlap=150):\n",
    "    print(\"Loading Pages:\", file_path)\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    doc_pages = loader.load()\n",
    "\n",
    "    print(\"Chunking pages...\", file_path)\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    doc_chunks = splitter.split_documents(doc_pages)\n",
    "\n",
    "    standard_chunks = []\n",
    "\n",
    "    for chunk in doc_chunks:\n",
    "        chunk_metadata_upd = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"page\": chunk.metadata.get(\"page\"),\n",
    "            \"source\": file_path,\n",
    "            \"title\": os.path.basename(file_path) \n",
    "        }\n",
    "\n",
    "        standard_chunks.append(Document(\n",
    "            page_content=chunk.page_content,\n",
    "            metadata=chunk_metadata_upd\n",
    "        ))\n",
    "        \n",
    "    print(\"Finished processing --------\", file_path)\n",
    "    return standard_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\attention_paper.pdf', 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\cnn_paper.pdf', 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\resnet_paper.pdf', 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf']\n"
     ]
    }
   ],
   "source": [
    "pdf_files = glob(\"C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs/*.pdf\")\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pages: C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\attention_paper.pdf\n",
      "Chunking pages... C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\attention_paper.pdf\n",
      "Finished processing -------- C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\attention_paper.pdf\n",
      "Loading Pages: C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\cnn_paper.pdf\n",
      "Chunking pages... C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\cnn_paper.pdf\n",
      "Finished processing -------- C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\cnn_paper.pdf\n",
      "Loading Pages: C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\resnet_paper.pdf\n",
      "Chunking pages... C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\resnet_paper.pdf\n",
      "Finished processing -------- C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\resnet_paper.pdf\n",
      "Loading Pages: C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\vision_transformer.pdf\n",
      "Chunking pages... C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\vision_transformer.pdf\n",
      "Finished processing -------- C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\vision_transformer.pdf\n"
     ]
    }
   ],
   "source": [
    "paper_docs = []\n",
    "\n",
    "for fp in pdf_files:\n",
    "    paper_docs.extend(create_standard_chunks(file_path=fp,chunk_size=1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Lenght of Documents --------- 1967\n"
     ]
    }
   ],
   "source": [
    "total_chunks = wikipedia_documents + paper_docs\n",
    "print(\"------ Lenght of Documents ---------\",len(total_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhavi\\OneDrive\\Desktop\\langhcain_learning\\faang\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\bhavi\\OneDrive\\Desktop\\langhcain_learning\\faang\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----EMBEDDINGS CREATED ---------]\n"
     ]
    }
   ],
   "source": [
    "# Indexing Documents and chunk embeddings in Vector DB \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en')\n",
    "\n",
    "chroma_db = Chroma.from_documents(documents=total_chunks,\n",
    "                                  embedding=embedding_model,\n",
    "                                  collection_metadata={\"hnsw:space\":\"cosine\"},\n",
    "                                  persist_directory=\"./wikipedia_db\")\n",
    "\n",
    "print(\"[----EMBEDDINGS CREATED ---------]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similarity and bm25 Retriever initalizes ----\n"
     ]
    }
   ],
   "source": [
    "# doing similarity based retrieval \n",
    "from langchain_community.retrievers import BM25Retriever \n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                              search_kwargs={\"k\":5})\n",
    "\n",
    "bm25_retrievers = BM25Retriever.from_documents(documents=total_chunks,\n",
    "                                               k=5)\n",
    "print(\"--- Similarity and bm25 Retriever initalizes ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000001E869706750>, k=5), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001E82D806290>, search_kwargs={'k': 5})], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reciprocal rank Fusion \n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers = [bm25_retrievers,similarity_retriever],\n",
    "    weights = [0.5,0.5]\n",
    ")\n",
    "ensemble_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhavi\\OneDrive\\Desktop\\langhcain_learning\\faang\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContextualCompressionRetriever(base_compressor=CrossEncoderReranker(model=HuggingFaceCrossEncoder(client=<sentence_transformers.cross_encoder.CrossEncoder.CrossEncoder object at 0x000001E86973D310>, model_name='BAAI/bge-reranker-v2-m3', model_kwargs={}), top_n=5), base_retriever=EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000001E869706750>, k=5), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001E82D806290>, search_kwargs={'k': 5})], weights=[0.5, 0.5]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chained Retrieval with Reranker \n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "reranker_compression = CrossEncoderReranker(model=reranker\n",
    "                                            ,top_n=5)\n",
    "\n",
    "final_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever = ensemble_retriever,  # BM25 + similarity search \n",
    "    base_compressor = reranker_compression # Re-ranker\n",
    "\n",
    ")\n",
    "final_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display ,Markdown\n",
    "\n",
    "def display_docs(docs):\n",
    "    for doc in docs:\n",
    "        print(\"------- META DATA ----------:\",doc.metadata)\n",
    "        print(\"-------- CONTENT BRIEF ---------\")\n",
    "        display(Markdown(doc.page_content[:500]))\n",
    "        print()\n",
    "        print(\"-----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- META DATA ----------: {'title': 'Machine learning', 'id': '564928', 'source': 'wikipedia', 'page': 1}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designin"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'page': 1, 'title': 'Deep learning', 'id': '663523', 'source': 'wikipedia'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, i"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'title': 'Supervised learning', 'page': 1, 'id': '359370', 'source': 'wikipedia'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'page': 1, 'title': 'Reinforcement learning', 'id': '610032', 'source': 'wikipedia'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning (RL) is teaching a \"software agent\" how to behave in an environment by telling it how good it's doing. It is an area of machine learning inspired by behaviorist psychology. Reinforcement learning is different from supervised learning because the correct inputs and outputs are never shown. Also, reinforcement learning usually learns as it goes (online learning) unlike supervised learning. This means an agent has to choose between exploring and sticking with what it knows be"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'title': 'Jaime Carbonell', 'id': '740974', 'source': 'wikipedia', 'page': 1}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Jaime Guillermo Carbonell (July 29, 1953 – February 28, 2020) was an American computer scientist. His works focused on natural language processing tools and technologies. He earned his B.S. degrees in Physics and in Mathematics from MIT in 1975 and did his Ph.D. under Dr. Roger Schank at Yale University in 1979. He joined Carnegie Mellon University as an assistant professor of computer science in 1979 and lived in Pittsburgh from then. He was affiliated with the Language Technologies Institute, "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Machine Learning ?\"\n",
    "tops_docs = final_retriever.invoke(query)\n",
    "display_docs(tops_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- META DATA ----------: {'id': '301cc692-ce5e-453c-aa39-d3724f38ce3b', 'page': 2, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Published as a conference paper at ICLR 2021\n",
       "Transformer Encoder\n",
       "MLP \n",
       "Head\n",
       "Vision Transformer (ViT)\n",
       "*\n",
       "Linear Projection of Flattened Patches\n",
       "* Extra learnable\n",
       "     [ cl ass]  embedding\n",
       "1\n",
       "2\n",
       "3\n",
       "4\n",
       "5\n",
       "6\n",
       "7\n",
       "8\n",
       "9\n",
       "0\n",
       "Patch + Position \n",
       "Embedding\n",
       "Class\n",
       "Bird\n",
       "Ball\n",
       "Car\n",
       "...\n",
       "Embedded \n",
       "Patches\n",
       "Multi-Head \n",
       "Attention\n",
       "Norm\n",
       "MLP\n",
       "Norm\n",
       "+\n",
       "L x\n",
       "+\n",
       "Transformer Encoder\n",
       "Figure 1: Model overview. We split an image into ﬁxed-size patches, linearly embed each of them,\n",
       "add position embeddings, and feed the resulting sequence of vect"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'id': '63c5851c-4977-440e-8d14-8a2a9ac86390', 'page': 7, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "tational budgets, but the difference vanishes for larger models. This result is somewhat surprising,\n",
       "since one might expect convolutional local feature processing to assist ViT at any size. Third, Vision\n",
       "Transformers appear not to saturate within the range tried, motivating future scaling efforts.\n",
       "4.5\n",
       "INSPECTING VISION TRANSFORMER\n",
       "Input\n",
       "Attention\n",
       "Figure 6: Representative ex-\n",
       "amples of attention from the\n",
       "output token to the input\n",
       "space. See Appendix D.7 for\n",
       "details.\n",
       "To begin to understand how the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'id': '611763c7-13d4-4272-a632-100a8963675d', 'page': 8, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "5\n",
       "CONCLUSION\n",
       "We have explored the direct application of Transformers to image recognition. Unlike prior works\n",
       "using self-attention in computer vision, we do not introduce image-speciﬁc inductive biases into\n",
       "the architecture apart from the initial patch extraction step. Instead, we interpret an image as a\n",
       "sequence of patches and process it by a standard Transformer encoder as used in NLP. This simple,\n",
       "yet scalable, strategy works surprisingly well when coupled with pre-training on large datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'page': 6, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf', 'title': 'vision_transformer.pdf', 'id': '5c9ecfc5-6518-4f66-bd1f-7e156063d5be'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Published as a conference paper at ICLR 2021\n",
       "ImageNet\n",
       "ImageNet-21k\n",
       "JFT-300M\n",
       "Pre-training dataset\n",
       "70\n",
       "75\n",
       "80\n",
       "85\n",
       "90\n",
       "ImageNet Top1 Accuracy [%]\n",
       "BiT\n",
       "ViT-B/32\n",
       "ViT-B/16\n",
       "ViT-L/32\n",
       "ViT-L/16\n",
       "ViT-H/14\n",
       "Figure 3:\n",
       "Transfer to ImageNet.\n",
       "While\n",
       "large ViT models perform worse than BiT\n",
       "ResNets (shaded area) when pre-trained on\n",
       "small datasets, they shine when pre-trained on\n",
       "larger datasets. Similarly, larger ViT variants\n",
       "overtake smaller ones as the dataset grows.\n",
       "10 M\n",
       "30 M\n",
       "100 M\n",
       "300 M\n",
       "Number of JFT pre-training samp"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'id': '339f5aab-85e0-4e8e-99af-d9e10beb8e65', 'page': 3, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "the patches can have spatial size 1x1, which means that the input sequence is obtained by simply\n",
       "ﬂattening the spatial dimensions of the feature map and projecting to the Transformer dimension.\n",
       "The classiﬁcation input embedding and position embeddings are added as described above.\n",
       "3.2\n",
       "FINE-TUNING AND HIGHER RESOLUTION\n",
       "Typically, we pre-train ViT on large datasets, and ﬁne-tune to (smaller) downstream tasks. For\n",
       "this, we remove the pre-trained prediction head and attach a zero-initialized D × K f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is difference between Vision Transformer and Normal Trnasformer ?\"\n",
    "tops_docs = final_retriever.invoke(query)\n",
    "display_docs(tops_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- META DATA ----------: {'page': 9, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\attention_paper.pdf', 'title': 'attention_paper.pdf', 'id': '438cc259-dcb6-4ac3-84c4-db96fda87d8b'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "arXiv:1607.06450, 2016.\n",
       "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\n",
       "learning to align and translate. CoRR, abs/1409.0473, 2014.\n",
       "[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\n",
       "machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
       "[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\n",
       "reading. arXiv preprint arXiv:1601.06733, 2016.\n",
       "10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'page': 1, 'source': 'wikipedia', 'id': '125565', 'title': 'Extensible Messaging and Presence Protocol'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Extensible Messaging and Presence Protocol (XMPP) (formerly named Jabber) is a protocol for instant messaging. It is inspired by XML. It is different to most protocols because it is an open standard. This means that anybody who has a domain name and an internet connection can run their own server. Most of the software and the clients are open source. Other software such as Google Talk and the Gizmo5 use the XMPP protocol. It has been installed on thousands of servers across the internet. There a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'page': 1, 'id': '168810', 'title': 'Keyhole Markup Language', 'source': 'wikipedia'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Keyhole Markup Language is a file format for displaying data on maps. In the same way that a Web browser displays web pages written with HTML, KML draws data on maps like Google Maps and virtual globes like Google Earth. It is an international standard , maintained by the Open Geospatial Consortium ."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'title': 'attention_paper.pdf', 'page': 11, 'source': 'C:/Users/bhavi/OneDrive/Desktop/langhcain_learning/RAG/rag_docs\\\\attention_paper.pdf', 'id': '5aaa4199-7af9-4ce7-a58a-68efa6ecdc6b'}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "translation system: Bridging the gap between human and machine translation. arXiv preprint\n",
       "arXiv:1609.08144, 2016.\n",
       "[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\n",
       "fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n",
       "[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\n",
       "shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\n",
       "1: Long Papers), pages 434–443."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "------- META DATA ----------: {'title': 'Billboard Hot 100', 'id': '128360', 'source': 'wikipedia', 'page': 1}\n",
      "-------- CONTENT BRIEF ---------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The \"Billboard\" Hot 100 is a list of the current most well-liked music made by \"Billboard\" magazine. Rankings are based on radio play and sales; the tracking week for sales is each Monday to Sunday, while for radio play it is Wednesday to Tuesday. A new chart is compiled and officially released to the public by \"Billboard\" on Thursday. Each chart is dated with the \"week-ending\" date of the Saturday two weeks after. Example: The first number one song of the Hot 100 was \"Poor Little Fool\" by Ricky"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is langchain ?\"\n",
    "tops_docs = final_retriever.invoke(query)\n",
    "display_docs(tops_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
